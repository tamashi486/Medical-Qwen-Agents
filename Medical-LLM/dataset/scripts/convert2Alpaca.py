import json
import random
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
INPUT_FILE = "./huatuoqa-dataset/validation_datasets.jsonl"  # ä½ çš„åŸå§‹æ–‡ä»¶
OUTPUT_FILE = "data/validation_datasets.jsonl"    # è½¬æ¢åçš„æ–‡ä»¶

# ç³»ç»Ÿæç¤ºè¯æ± ï¼šè®©æ¨¡å‹åœ¨å¾®è°ƒé˜¶æ®µå°±å›ºå®šäººè®¾
SYSTEM_PROMPTS = [
    "ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŒ»ç–—ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›å‡†ç¡®ã€è¯¦å°½ä¸”å®‰å…¨çš„åŒ»ç–—å»ºè®®ã€‚",
    "ä½œä¸ºä¸€åç»éªŒä¸°å¯Œçš„åŒ»ç”Ÿï¼Œè¯·å›ç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚å¦‚æœé—®é¢˜æ¶‰åŠå±é™©æ“ä½œï¼Œè¯·ç»™å‡ºå®‰å…¨è­¦å‘Šã€‚",
    "ä¸‹é¢æ˜¯ä¸€ä¸ªå…³äºåŒ»ç–—å¥åº·çš„é—®é¢˜ï¼Œè¯·åˆ©ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†ç»™å‡ºè§£ç­”ã€‚",
]

def convert_data():
    print(f"ğŸš€ å¼€å§‹åŠ è½½åŸå§‹æ•°æ®: {INPUT_FILE} ...")
    
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            raw_data = [json.loads(line) for line in f if line.strip()]
                
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šè¯»å–æ–‡ä»¶å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„æˆ–æ–‡ä»¶æ ¼å¼ã€‚\né”™è¯¯ä¿¡æ¯: {e}")
        return

    formatted_data = []
    skipped_count = 0

    print("ğŸ”„ æ­£åœ¨è§£æåµŒå¥—ç»“æ„å¹¶æ¸…æ´—æ•°æ®...")
    
    for entry in tqdm(raw_data):
        # 1. è§£æ Question (å¤„ç†åµŒå¥—åˆ—è¡¨)
        # æ•°æ®æ ·ä¾‹: "questions": [["é—®æ³•1", "é—®æ³•2"]]
        qs = entry.get("questions", [])
        
        question_text = ""
        
        # é€»è¾‘ï¼šæˆ‘ä»¬éœ€è¦æå–å‡ºå­—ç¬¦ä¸²ç±»å‹çš„é—®å¥
        if isinstance(qs, list) and len(qs) > 0:
            first_group = qs[0] # å–å‡º ["é—®æ³•1", "é—®æ³•2"]
            if isinstance(first_group, list) and len(first_group) > 0:
                # ç­–ç•¥ï¼šé€šå¸¸å–ç¬¬ä¸€ä¸ªé—®æ³•ä½œä¸ºæ ‡å‡† Inputï¼Œå› ä¸ºå®ƒæœ€è§„èŒƒ
                # è¿›é˜¶ç­–ç•¥ï¼ˆå¯é€‰ï¼‰ï¼šä½ å¯ä»¥éšæœºé€‰ä¸€ä¸ªé—®æ³•ï¼Œå¢åŠ æ•°æ®çš„ä¸°å¯Œæ€§ (Data Augmentation)
                question_text = first_group[0] 
            elif isinstance(first_group, str):
                # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šä¸‡ä¸€æœ‰äº›æ•°æ®ä¸æ˜¯åµŒå¥—åˆ—è¡¨ï¼Œè€Œæ˜¯ç›´æ¥ ["é—®æ³•1"]
                question_text = first_group
        
        # 2. è§£æ Answer
        # æ•°æ®æ ·ä¾‹: "answers": ["ç­”æ¡ˆå†…å®¹"]
        ans = entry.get("answers", [])
        
        answer_text = ""
        if isinstance(ans, list) and len(ans) > 0:
            answer_text = ans[0] # å–å‡ºç­”æ¡ˆå­—ç¬¦ä¸²
        elif isinstance(ans, str):
            answer_text = ans

        # 3. æ•°æ®æ¸…æ´—ä¸éªŒè¯
        # å¦‚æœæå–å¤±è´¥ï¼Œæˆ–è€…æ–‡æœ¬è¿‡çŸ­ï¼Œåˆ™è·³è¿‡
        if not question_text or not answer_text:
            skipped_count += 1
            continue
            
        if not isinstance(question_text, str) or not isinstance(answer_text, str):
            skipped_count += 1
            continue

        if len(answer_text) < 5: # è¿‡æ»¤æ‰ "æ˜¯"ã€"å¥½" è¿™ç§æ— æ„ä¹‰å›ç­”
            skipped_count += 1
            continue

        # 4. æ„å»º Alpaca æ ¼å¼
        alpaca_entry = {
            # Instruction = ç³»ç»Ÿæç¤º + ç”¨æˆ·é—®é¢˜
            "instruction": f"{random.choice(SYSTEM_PROMPTS)}\n\nç”¨æˆ·é—®é¢˜ï¼š{question_text}",
            "input": "", # åä½—æ•°æ®é›†æ²¡æœ‰é¢å¤–çš„ä¸Šä¸‹æ–‡ Contextï¼ŒInput ç•™ç©º
            "output": answer_text
        }
        
        formatted_data.append(alpaca_entry)

    # ä¿å­˜
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {OUTPUT_FILE} ...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(formatted_data, f, ensure_ascii=False, indent=2)

    print("=" * 40)
    print(f"âœ… è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ“Š åŸå§‹æ¡ç›®æ•°: {len(raw_data)}")
    print(f"ğŸ—‘ï¸ æ¸…æ´—/å¼‚å¸¸æ¡ç›®: {skipped_count}")
    print(f"âœ¨ æœ‰æ•ˆè®­ç»ƒæ•°æ®: {len(formatted_data)}")
    print("=" * 40)
    
    # æ‰“å°ä¸€æ¡æ ·ä¾‹ä¾›æ£€æŸ¥
    if len(formatted_data) > 0:
        print("ğŸ” æ•°æ®æ ·ä¾‹ preview:")
        print(json.dumps(formatted_data[0], ensure_ascii=False, indent=2))

if __name__ == "__main__":
    convert_data()