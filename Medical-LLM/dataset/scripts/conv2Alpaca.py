import json
import random
import os
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
# è¾“å…¥ï¼šåˆ—è¡¨å½¢å¼ï¼Œå¡«å…¥ä½ å®žé™…çš„æ–‡ä»¶å
INPUT_FILES_TRAIN = ["/data/home/yihui/LLM/Medical-LLM/dataset/huatuoqa-dataset/train_datasets.jsonl", "/data/home/yihui/LLM/Medical-LLM/dataset/huatuoqa-dataset/validation_datasets.jsonl"]  # å°†è®­ç»ƒå’ŒéªŒè¯åˆå¹¶ç”¨äºŽè®­ç»ƒ
INPUT_FILE_TEST = "/data/home/yihui/LLM/Medical-LLM/dataset/huatuoqa-dataset/test_datasets.jsonl"                   # æµ‹è¯•é›†å•ç‹¬å¤„ç†

OUTPUT_FILE_TRAIN = "/data/home/yihui/LLM/Medical-LLM/dataset/data/train.jsonl"  # è¾“å‡ºçš„è®­ç»ƒæ•°æ®
OUTPUT_FILE_TEST = "/data/home/yihui/LLM/Medical-LLM/dataset/data/test.jsonl"    # è¾“å‡ºçš„æµ‹è¯•æ•°æ®

SYSTEM_PROMPTS = [
    "ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŒ»ç–—ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›å‡†ç¡®ã€è¯¦å°½ä¸”å®‰å…¨çš„åŒ»ç–—å»ºè®®ã€‚",
    "ä½œä¸ºä¸€åç»éªŒä¸°å¯Œçš„åŒ»ç”Ÿï¼Œè¯·å›žç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚å¦‚æžœé—®é¢˜æ¶‰åŠå±é™©æ“ä½œï¼Œè¯·ç»™å‡ºå®‰å…¨è­¦å‘Šã€‚",
    "ä¸‹é¢æ˜¯ä¸€ä¸ªå…³äºŽåŒ»ç–—å¥åº·çš„é—®é¢˜ï¼Œè¯·åˆ©ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†ç»™å‡ºè§£ç­”ã€‚",
]

def process_file(file_path, is_test=False):
    """è¯»å–å¹¶æ¸…æ´—å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ž Alpaca æ ¼å¼åˆ—è¡¨"""
    formatted_data = []
    
    if not os.path.exists(file_path):
        print(f"âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
        return []

    with open(file_path, 'r', encoding='utf-8') as f:
        raw_data = [json.loads(line) for line in f if line.strip()]

    for entry in raw_data:
        # 1. è§£æž Question
        qs = entry.get("questions", [])
        question_text = ""
        if isinstance(qs, list) and len(qs) > 0:
            first_group = qs[0]
            if isinstance(first_group, list) and len(first_group) > 0:
                question_text = first_group[0]
            elif isinstance(first_group, str):
                question_text = first_group
        
        # 2. è§£æž Answer
        ans = entry.get("answers", [])
        answer_text = ""
        if isinstance(ans, list) and len(ans) > 0:
            answer_text = ans[0]
        elif isinstance(ans, str):
            answer_text = ans

        # 3. æ¸…æ´—
        if not question_text or not answer_text:
            continue
        if len(answer_text) < 5:
            continue

        # 4. æž„å»º Alpaca
        # å¦‚æžœæ˜¯æµ‹è¯•é›†ï¼Œä¸éœ€è¦éšæœº promptï¼Œç”¨å›ºå®šçš„æ–¹ä¾¿å¯¹æ¯”ï¼Œæˆ–è€… instruction ä¿æŒä¸€è‡´
        instruction = f"{random.choice(SYSTEM_PROMPTS)}\n\nç”¨æˆ·é—®é¢˜ï¼š{question_text}"
        
        alpaca_entry = {
            "instruction": instruction,
            "input": "",
            "output": answer_text
        }
        formatted_data.append(alpaca_entry)
        
    return formatted_data

def main():
    # --- å¤„ç†è®­ç»ƒé›† (Train + Dev) ---
    print("ðŸš€ æ­£åœ¨åˆå¹¶å¤„ç† [Train + Val] æ•°æ®...")
    all_train_data = []
    for f_path in INPUT_FILES_TRAIN:
        print(f"  - è¯»å– {f_path} ...")
        all_train_data.extend(process_file(f_path))
    
    print(f"ðŸ’¾ ä¿å­˜è®­ç»ƒé›†: {OUTPUT_FILE_TRAIN} (å…± {len(all_train_data)} æ¡)")
    with open(OUTPUT_FILE_TRAIN, 'w', encoding='utf-8') as f:
        for item in all_train_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    # --- å¤„ç†æµ‹è¯•é›† (Test) ---
    print("ðŸš€ æ­£åœ¨å¤„ç† [Test] æ•°æ®...")
    all_test_data = process_file(INPUT_FILE_TEST, is_test=True)
    
    print(f"ðŸ’¾ ä¿å­˜æµ‹è¯•é›†: {OUTPUT_FILE_TEST} (å…± {len(all_test_data)} æ¡)")
    with open(OUTPUT_FILE_TEST, 'w', encoding='utf-8') as f:
        for item in all_test_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print("âœ… æ‰€æœ‰æ•°æ®å¤„ç†å®Œæ¯•ï¼")

if __name__ == "__main__":
    main()