import json
import os
from tqdm import tqdm
from vllm import LLM, SamplingParams
from transformers import AutoTokenizer

# ================= é…ç½®åŒºåŸŸ =================
# 1. æ¨¡å‹è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ æœ¬åœ°å®é™…çš„ Qwen3-32B è·¯å¾„)
MODEL_PATH = "../../qwen3-32B" 

# 2. è¾“å…¥æ•°æ® (ä¸Šä¸€é˜¶æ®µç”Ÿæˆçš„ Alpaca æ ¼å¼è®­ç»ƒæ•°æ®)
INPUT_FILE = "data/train.jsonl"

# 3. è¾“å‡ºæ–‡ä»¶ (DPO æ ¼å¼ JSONL)
OUTPUT_FILE = "data/dpo.jsonl"

# 4. ç¡¬ä»¶é…ç½®
TENSOR_PARALLEL_SIZE = 4  # æ ¸å¿ƒï¼šä½¿ç”¨4å¼ å¡å¹¶è¡Œæ¨ç†

def generate_dpo_dataset():
    print(f"ğŸš€ åˆå§‹åŒ– vLLM å¼•æ“ï¼ŒåŠ è½½æ¨¡å‹: {MODEL_PATH}")
    print(f"âš¡ ä½¿ç”¨ GPU æ•°é‡: {TENSOR_PARALLEL_SIZE}")

    # --- 1. åˆå§‹åŒ– Tokenizer å’Œ vLLM ---
    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
        # åˆå§‹åŒ– vLLMï¼Œå¼ºåˆ¶ä½¿ç”¨ BFloat16 ä»¥èŠ‚çœæ˜¾å­˜å¹¶åŠ é€Ÿ
        llm = LLM(
            model=MODEL_PATH,
            tensor_parallel_size=TENSOR_PARALLEL_SIZE,
            trust_remote_code=True,
            dtype="bfloat16",
            gpu_memory_utilization=0.90, #ä»¥æ­¤ç•™å‡ºä¸€ç‚¹ç©ºé—´
        )
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # --- 2. è¯»å–è¾“å…¥æ•°æ® ---
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        return

    print(f"ğŸ“– è¯»å–è¾“å…¥æ•°æ®: {INPUT_FILE} ...")
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        # å‡è®¾è¾“å…¥æ˜¯æ ‡å‡†çš„ Alpaca åˆ—è¡¨æ ¼å¼ [{"instruction":..., "output":...}]
        sft_data = json.load(f)

    # ä»…ä¸ºäº†æ¼”ç¤ºæˆ–å¿«é€ŸéªŒè¯ï¼Œå¯ä»¥å–å‰ 5000 æ¡ï¼Œå¦‚æœå…¨é‡è·‘å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
    # æ—¢ç„¶ä½ æœ‰4å¼ å¡ï¼Œå…¨é‡è·‘ä¹Ÿå¾ˆå¿«ã€‚è¿™é‡Œä¸åšåˆ‡ç‰‡ï¼Œè·‘å…¨é‡ã€‚
    # sft_data = sft_data[:5000] 

    # --- 3. æ„é€  Prompt ---
    print("ğŸ”„ æ­£åœ¨æ„å»º Prompts ...")
    prompts = []
    original_entries = [] # ç”¨äºä¿å­˜å¯¹åº”å…³ç³»

    for entry in sft_data:
        instruction = entry.get("instruction", "")
        input_text = entry.get("input", "")
        
        # æ„é€ ç¬¦åˆ Qwen å¯¹è¯æ¨¡ç‰ˆçš„ Prompt
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è®©æ¨¡å‹ç”Ÿæˆç­”æ¡ˆï¼Œä½œä¸º Negative (Rejected)
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": instruction + input_text}
        ]
        
        # ä½¿ç”¨ apply_chat_template å°†å¯¹è¯è½¬ä¸º prompt string
        # tokenize=False è¡¨ç¤ºè¿”å›å­—ç¬¦ä¸²
        text_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)
        
        prompts.append(text_prompt)
        original_entries.append(entry)

    # --- 4. æ‰¹é‡ç”Ÿæˆ (Inference) ---
    print(f"âš¡ å¼€å§‹æ‰¹é‡ç”Ÿæˆ Rejected æ ·æœ¬ (å…± {len(prompts)} æ¡)...")
    
    # é‡‡æ ·å‚æ•°ï¼šç¨å¾®è°ƒé«˜ temperature (0.7-0.9) è®©æ¨¡å‹äº§ç”Ÿå¤šæ ·æ€§ï¼Œ
    # è¿™æ ·æ›´å®¹æ˜“ç”Ÿæˆå’Œæ ‡å‡†ç­”æ¡ˆä¸ä¸€æ ·çš„â€œæ¬¡ä¼˜è§£â€
    sampling_params = SamplingParams(
        temperature=0.8,
        top_p=0.95,
        max_tokens=512, # é™åˆ¶é•¿åº¦ï¼Œé˜²æ­¢ç”Ÿæˆå¤ªæ…¢
        stop=["<|endoftext|>", "<|im_end|>"]
    )

    outputs = llm.generate(prompts, sampling_params)

    # --- 5. ç»„è£… DPO æ•°æ®å¹¶ä¿å­˜ ---
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ DPO æ•°æ®åˆ°: {OUTPUT_FILE} ...")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for i, output in enumerate(tqdm(outputs)):
            # vLLM çš„è¾“å‡ºå¯¹è±¡
            generated_text = output.outputs[0].text.strip()
            
            original_entry = original_entries[i]
            
            # DPO æ•°æ®æ ¼å¼æ ‡å‡†ï¼š
            # prompt: é—®é¢˜
            # chosen: åŸå§‹æ•°æ®é›†çš„ç­”æ¡ˆ (Gold Standard)
            # rejected: æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ (Predicted)
            
            dpo_entry = {
                "instruction": original_entry["instruction"],
                "input": original_entry["input"],
                "chosen": original_entry["output"], # æ­£æ ·æœ¬
                "rejected": generated_text          # è´Ÿæ ·æœ¬
            }

            # ç®€å•çš„è¿‡æ»¤é€»è¾‘ï¼šå¦‚æœç”Ÿæˆçš„è·Ÿæ ‡å‡†ç­”æ¡ˆå®Œå…¨ä¸€æ ·ï¼Œå°±æ²¡å¿…è¦è®­ç»ƒäº†
            # ä½†åœ¨å¤§æ¨¡å‹é‡Œå®Œå…¨ä¸€æ ·çš„æ¦‚ç‡æä½
            if dpo_entry["chosen"] == dpo_entry["rejected"]:
                continue

            # å†™å…¥ JSONL (æ¯è¡Œä¸€ä¸ª JSON)
            f.write(json.dumps(dpo_entry, ensure_ascii=False) + "\n")

    print("="*40)
    print("âœ… DPO æ•°æ®æ„å»ºå®Œæˆï¼")
    print(f"ğŸ“Š æ ·æœ¬æ€»æ•°: {len(outputs)}")
    print("="*40)

if __name__ == "__main__":
    generate_dpo_dataset()