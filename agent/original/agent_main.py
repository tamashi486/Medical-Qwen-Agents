import os
import time
import logging
from typing import List, Dict, Any

import torch
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.tools import tool, StructuredTool
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.messages import BaseMessage

# é…ç½®æ—¥å¿— (é¢è¯•ç‚¹: å¯è§‚æµ‹æ€§)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MedicalAgentSystem:
    """
    ä¼ä¸šçº§åŒ»ç–— Agent ç³»ç»Ÿå°è£…
    ç‰¹ç‚¹: å•ä¾‹æ¨¡å¼æ€æƒ³ã€æ”¯æŒ Rerankã€æ”¯æŒå¯¹è¯è®°å¿†ã€å¼‚æ­¥è°ƒç”¨
    """
    def __init__(self, 
                 db_path: str, 
                 embedding_model_path: str, 
                 vllm_api_base: str, 
                 model_name: str,
                 device: str = None):
        
        self.db_path = db_path
        self.embedding_model_path = embedding_model_path
        self.vllm_api_base = vllm_api_base
        self.model_name = model_name
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        # å†…éƒ¨ç»„ä»¶çŠ¶æ€
        self.llm = None
        self.retriever = None
        self.agent_executor = None
        # ç”¨äºå­˜å‚¨ä¸åŒ SessionID çš„èŠå¤©è®°å½• (ç”Ÿäº§ç¯å¢ƒé€šå¸¸å­˜ Redis)
        self.chat_histories: Dict[str, ChatMessageHistory] = {}
        
        self._initialize_system()

    def _initialize_system(self):
        """åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶"""
        try:
            logger.info(f"ğŸš€ åˆå§‹åŒ–ç³»ç»Ÿ... è®¾å¤‡: {self.device}")
            start_time = time.time()

            # 1. Embedding & VectorDB
            embeddings = HuggingFaceEmbeddings(
                model_name=self.embedding_model_path, 
                model_kwargs={'device': self.device}
            )
            
            # ä½¿ç”¨ Chroma
            vector_db = Chroma(persist_directory=self.db_path, embedding_function=embeddings)
            
            # é¢è¯•ç‚¹: è½¬æ¢ä¸º Retrieverï¼Œè·å– Top-10 æ­¤æ—¶ä¸ºäº†åé¢çš„ Rerank åšå‡†å¤‡
            # å¦‚æœæ²¡æœ‰ Rerank æ¨¡å‹ï¼Œè¿™é‡Œç›´æ¥ K=3 ä¹Ÿå¯ä»¥ï¼Œä½†é¢è¯•è¦è¯´"ä¸ºäº†å¬å›ç‡è®¾å¤§äº† K"
            self.retriever = vector_db.as_retriever(search_kwargs={"k": 10})

            # 2. LLM (vLLM)
            self.llm = ChatOpenAI(
                model=self.model_name,
                openai_api_key="EMPTY",
                openai_api_base=self.vllm_api_base,
                temperature=0.1, # åŒ»ç–—åœºæ™¯ä½ç†µ
                max_tokens=4096,
                streaming=True   # æ”¯æŒæµå¼è¾“å‡º
            )

            # 3. å·¥å…·é“¾æ³¨å†Œ
            tools = [self._create_search_tool(), self._create_bmi_tool()]

            # 4. Prompt è®¾è®¡ (é¢è¯•ç‚¹: Role, Constraints, Format)
            prompt = ChatPromptTemplate.from_messages([
                ("system", 
                 "ä½ æ˜¯ä¸€ä¸ªåä¸º'åé©¼'çš„ä¸“ä¸šåŒ»ç–—AIåŠ©æ‰‹ã€‚\n"
                 "æ ¸å¿ƒåŸåˆ™ï¼š\n"
                 "1. ã€å¾ªè¯åŒ»å­¦ã€‘å›ç­”å¿…é¡»ä¸¥æ ¼åŸºäºå·¥å…·æ£€ç´¢åˆ°çš„ã€è¯æ®ã€‘ã€‚å¦‚æœè¯æ®ä¸è¶³ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ã€‚\n"
                 "2. ã€å¼•ç”¨æ¥æºã€‘åœ¨å›ç­”ç»“å°¾ï¼Œå¿…é¡»åˆ—å‡ºå‚è€ƒçš„è¯æ®æ¥æºï¼ˆå¦‚ä¹¦ç±åç§°ï¼‰ã€‚\n"
                 "3. ã€å®‰å…¨åˆè§„ã€‘ä¸¥ç¦æä¾›å…·ä½“çš„å¤„æ–¹å»ºè®®ï¼ˆå¦‚'æ¯å¤©åƒ3æ¬¡'ï¼‰ï¼Œåªèƒ½æä¾›é€šç”¨çš„æ²»ç–—æ–¹æ¡ˆå‚è€ƒã€‚\n"
                 "4. ã€æ‹’ç»å›ç­”ã€‘å¯¹äºéåŒ»ç–—æˆ–è¿æ³•é—®é¢˜ï¼ˆå¦‚åˆ¶é€ æ¯’è¯ï¼‰ï¼Œè¯·ç›´æ¥æ‹’ç»ã€‚"),
                MessagesPlaceholder(variable_name="chat_history"), # è®°å¿†æ§½ä½
                ("user", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])

            # 5. æ„å»º Agent
            agent = create_tool_calling_agent(self.llm, tools, prompt)
            
            # 6. åŒ…è£…è®°å¿†åŠŸèƒ½çš„æ‰§è¡Œå™¨
            raw_executor = AgentExecutor(
                agent=agent, 
                tools=tools, 
                verbose=True,
                return_intermediate_steps=True # è¿”å›ä¸­é—´æ­¥éª¤ä»¥ä¾¿è°ƒè¯•
            )
            
            # ä½¿ç”¨ RunnableWithMessageHistory ç®¡ç†å¤šè½®å¯¹è¯
            self.agent_executor = RunnableWithMessageHistory(
                raw_executor,
                self._get_session_history,
                input_messages_key="input",
                history_messages_key="chat_history",
            )

            logger.info(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.2f}s")

        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    def _get_session_history(self, session_id: str) -> ChatMessageHistory:
        """è·å–æˆ–åˆ›å»ºä¼šè¯å†å² (é¢è¯•ç‚¹: Session Management)"""
        if session_id not in self.chat_histories:
            self.chat_histories[session_id] = ChatMessageHistory()
        return self.chat_histories[session_id]

    # --- å·¥å…·å®šä¹‰ (ä½¿ç”¨é—­åŒ…æˆ–å®ä¾‹æ–¹æ³•) ---

    def _create_search_tool(self):
        @tool("search_medical_knowledge")
        def search_tool(query: str):
            """
            ã€å¿…é¡»ä½¿ç”¨ã€‘å½“ç”¨æˆ·è¯¢é—®å…·ä½“çš„ç–¾ç—…ã€ç—‡çŠ¶ã€è¯å“ã€ç¦å¿Œç—‡æˆ–æ²»ç–—æŒ‡å—æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚
            """
            logger.info(f"ğŸ” æ­£åœ¨æ£€ç´¢: {query}")
            
            # 1. ç²—æ’ (Recall)
            docs = self.retriever.invoke(query)
            if not docs:
                return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            
            # 2. (æ¨¡æ‹Ÿ) é‡æ’åº (Rerank) - é¢è¯•ç‚¹
            # åœ¨å®é™…å¤§å‚ä»£ç ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ BGE-Reranker æ¨¡å‹å¯¹ docs æ‰“åˆ†
            # sorted_docs = reranker.rank(query, docs)[:3] 
            # è¿™é‡Œä¸ºäº†ä»£ç å¯è¿è¡Œï¼Œæˆ‘ä»¬ç®€å•æˆªå–å‰ 3 ä¸ª
            final_docs = docs[:3]

            # 3. æ ¼å¼åŒ–è¾“å‡º (å¸¦å…ƒæ•°æ®) - é¢è¯•ç‚¹
            results = []
            for i, doc in enumerate(final_docs):
                source = doc.metadata.get('title', 'æœªçŸ¥æ¥æº')
                category = doc.metadata.get('category', 'é€šç”¨')
                content = doc.page_content.replace('\n', ' ')
                results.append(f"[è¯æ®{i+1}] (æ¥æº: {source} | åˆ†ç±»: {category}):\n{content}")
            
            return "\n\n".join(results)
        return search_tool

    def _create_bmi_tool(self):
        @tool("calculate_bmi")
        def bmi_tool(weight_kg: float, height_m: float):
            """è®¡ç®—ç”¨æˆ·çš„BMIæŒ‡æ•°ã€‚è¾“å…¥ä½“é‡(kg)å’Œèº«é«˜(m)ã€‚"""
            try:
                bmi = weight_kg / (height_m ** 2)
                status = "æ­£å¸¸"
                if bmi < 18.5: status = "åç˜¦"
                elif bmi > 24: status = "è¶…é‡"
                
                return f"BMIæ•°å€¼: {bmi:.2f}\nå¥åº·çŠ¶æ€: {status}\nå»ºè®®: è¯·ç»“åˆå…·ä½“èº«ä½“çŠ¶å†µå’¨è¯¢åŒ»ç”Ÿã€‚"
            except Exception as e:
                return f"è®¡ç®—å‡ºé”™: {str(e)}"
        return bmi_tool

    # --- å¯¹å¤–æ¥å£ ---

    def chat(self, user_input: str, session_id: str = "default_user"):
        """åŒæ­¥è°ƒç”¨æ¥å£"""
        try:
            response = self.agent_executor.invoke(
                {"input": user_input},
                config={"configurable": {"session_id": session_id}}
            )
            return response["output"]
        except Exception as e:
            logger.error(f"æ¨ç†é”™è¯¯: {e}")
            return "ç³»ç»Ÿæ­£å¦‚ç«å¦‚è¼åœ°ç»´ä¿®ä¸­..."

    async def achat(self, user_input: str, session_id: str = "default_user"):
        """å¼‚æ­¥è°ƒç”¨æ¥å£ (WebæœåŠ¡ä¸“ç”¨)"""
        try:
            response = await self.agent_executor.ainvoke(
                {"input": user_input},
                config={"configurable": {"session_id": session_id}}
            )
            return response["output"]
        except Exception as e:
            logger.error(f"å¼‚æ­¥æ¨ç†é”™è¯¯: {e}")
            return "ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚"

# --- å¯åŠ¨æµ‹è¯• ---
if __name__ == "__main__":
    # é…ç½®
    CONFIG = {
        "db_path": "/data/home/yihui/LLM/data/medical_embedding",
        "embedding_model_path": "/data/home/yihui/LLM/bge-m3",
        "vllm_api_base": "http://localhost:8000/v1",
        "model_name": "qwen-medical"
    }

    # å®ä¾‹åŒ–
    agent_system = MedicalAgentSystem(**CONFIG)

    # æµ‹è¯•å¤šè½®å¯¹è¯ (Memory æµ‹è¯•)
    session_id = "test_user_001"
    
    print("\n----- æµ‹è¯•å¼€å§‹ -----")
    q1 = "æ„Ÿå†’äº†å¤´ç—›è¯¥åƒä»€ä¹ˆè¯ï¼Ÿ"
    print(f"User: {q1}")
    print(f"Agent: {agent_system.chat(q1, session_id)}")
    
    print("\n----- æµ‹è¯•è®°å¿† -----")
    q2 = "åˆšæ‰æåˆ°çš„è¯æœ‰ä»€ä¹ˆå‰¯ä½œç”¨ï¼Ÿ" # è¿™é‡Œæ²¡æœ‰æè¯åï¼Œå¼ºä¾èµ– Memory
    print(f"User: {q2}")
    print(f"Agent: {agent_system.chat(q2, session_id)}")