import gradio as gr
import os
import sys
import time
import html
import base64
import io
import re
import uuid
import logging
import requests
import asyncio
from datetime import datetime
from typing import List, Tuple
from PIL import Image

# --- Environment Setup ---
os.environ['no_proxy'] = 'localhost,127.0.0.1,0.0.0.0'
os.environ['NO_PROXY'] = 'localhost,127.0.0.1,0.0.0.0'

# --- Configuration ---
MAX_MESSAGE_LENGTH = 16000
MAX_HISTORY_LENGTH = 50
MAX_FILE_SIZE = 10 * 1024 * 1024
MAX_OUTPUT_TOKENS = 8192
DEFAULT_OUTPUT_TOKENS = 2048
API_URL = "http://localhost:8081"

SUPPORTED_TEXT_EXTENSIONS = {'.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv'}
SUPPORTED_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}

# --- Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("WebUI")

# --- Helper Functions ---

def generate_session_id():
    """ä¸ºæ¯ä¸ª Tab ç”Ÿæˆå”¯ä¸€ä¼šè¯ ID"""
    return str(uuid.uuid4())

def init_session(session_id):
    """Initialize session ID if not present"""
    if not session_id:
        return str(uuid.uuid4())
    return session_id

def process_uploaded_file(file_path: str) -> Tuple[str, str]:
    if not file_path or not os.path.exists(file_path):
        return "", "æ–‡ä»¶ä¸å­˜åœ¨"
    
    file_size = os.path.getsize(file_path)
    if file_size > MAX_FILE_SIZE:
        return "", f"æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024:.1f}MB)"
    
    file_name = os.path.basename(file_path)
    file_ext = os.path.splitext(file_name)[1].lower()
    
    try:
        if file_ext in SUPPORTED_TEXT_EXTENSIONS:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            return content, f"ğŸ“„ æ–‡ä»¶: {file_name} ({file_size} bytes)"
        
        elif file_ext in SUPPORTED_IMAGE_EXTENSIONS:
            with Image.open(file_path) as img:
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                img.thumbnail((800, 800))
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                img_base64 = base64.b64encode(buffer.getvalue()).decode()
            return f"data:image/jpeg;base64,{img_base64}", f"ğŸ–¼ï¸ å›¾ç‰‡: {file_name}"
        
        return "", f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
    except Exception as e:
        return "", f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)[:100]}"

def get_timestamp() -> str:
    return datetime.now().strftime("%H:%M:%S")

def format_message(content: str, role: str) -> str:
    timestamp = get_timestamp()
    role_name = "æ‚¨" if role == "user" else "AI"
    return f"**[{timestamp}] {role_name}:** {content}"

def clean_content(content: str) -> str:
    """Remove timestamp and role prefix for processing"""
    return re.sub(r'\*\*\[.*?\] .*?:\*\* ', '', content)

def format_thinking(text: str) -> str:
    """Format <think> tags into collapsible details"""
    # Handle complete think blocks (support multiple blocks)
    pattern = r"<think>(.*?)</think>"
    
    def replace_func(match):
        content = match.group(1).strip()
        return f'''<details class="thought-bubble">
<summary>ğŸ§  æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</summary>
<div class="thought-content">{content}</div>
</details>'''
    
    formatted_text = re.sub(pattern, replace_func, text, flags=re.DOTALL)
    
    # Handle incomplete think block (streaming)
    if "<think>" in formatted_text and "</think>" not in formatted_text:
        parts = formatted_text.split("<think>", 1)
        pre_content = parts[0]
        think_content = parts[1]
        return f'''{pre_content}<details class="thought-bubble" open>
<summary>ğŸ§  æ­£åœ¨æ€è€ƒ...</summary>
<div class="thought-content">{think_content}</div>
</details>'''
        
    return formatted_text

def export_conversation(history: List[dict]) -> str:
    if not history:
        return "æš‚æ— å¯¹è¯è®°å½•"
    export_text = f"# å¯¹è¯è®°å½•å¯¼å‡º\nå¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    for msg in history:
        role = "ç”¨æˆ·" if msg["role"] == "user" else "AIåŠ©æ‰‹"
        content = clean_content(msg["content"])
        export_text += f"## {role}\n{content}\n\n"
    return export_text

def handle_export(history: List[dict]):
    if not history:
        return None, "âš ï¸ æš‚æ— å¯¹è¯è®°å½•å¯å¯¼å‡º"
    try:
        export_content = export_conversation(history)
        filename = f"conversation_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(export_content)
        return filename, f"âœ… å¯¹è¯å·²æˆåŠŸå¯¼å‡ºåˆ° {filename}"
    except Exception as e:
        return None, f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)[:50]}"

def copy_last_response(history: List[dict]):
    if not history:
        return "âš ï¸ æš‚æ— å¯¹è¯è®°å½•"
    for msg in reversed(history):
        if msg["role"] == "assistant":
            content = clean_content(msg["content"])
            return f"âœ… å·²å‡†å¤‡å¤åˆ¶: {content[:50]}..."
    return "âš ï¸ æœªæ‰¾åˆ°AIå›å¤"

def on_like(x: gr.LikeData, session_id: str):
    """æ”¶é›†ç”¨æˆ·ç‚¹èµ/ç‚¹è¸©æ•°æ®"""
    user_feedback = "Liked" if x.liked else "Disliked"
    logger.info(f"Feedback [{session_id}]: {user_feedback} | Message: {x.value[:50]}...")
    gr.Info(f"æ„Ÿè°¢åé¦ˆï¼å·²è®°å½• ({user_feedback})")

# --- Core Logic ---
async def chat_stream(
    message: str, 
    history: List[dict], 
    mode: str, 
    session_id: str,
    uploaded_file=None, 
    temperature=0.7, 
    max_tokens=DEFAULT_OUTPUT_TOKENS
):
    if not message.strip() and not uploaded_file:
        yield history
        return

    # Prepare Input
    file_content, file_info = "", ""
    if uploaded_file:
        file_content, file_info = process_uploaded_file(uploaded_file.name)
    
    display_message = message
    if file_info:
        display_message += f"\n\n[{file_info}]"
    
    agent_input = message
    if file_content:
        agent_input += f"\n\n[æ–‡ä»¶å†…å®¹]\n{file_content}"

    # Update History (User)
    new_history = history + [{"role": "user", "content": format_message(display_message, "user")}]
    
    # Placeholder for AI
    loading_msg = "â³ æ­£åœ¨æ€è€ƒå¹¶æŸ¥è¯¢çŸ¥è¯†åº“..." if mode == "Agentæ¨¡å¼" else "â³ æ­£åœ¨ç”Ÿæˆ..."
    new_history.append({"role": "assistant", "content": format_message(loading_msg, "assistant")})
    yield new_history

    try:
        api_mode = "agent" if mode == "Agentæ¨¡å¼" else "chat"
        payload = {
            "message": agent_input,
            "session_id": session_id,
            "mode": api_mode
        }
        
        # Call API asynchronously using thread, with timeout to avoid long blocking
        response = await asyncio.to_thread(
            requests.post, 
            f"{API_URL}/chat", 
            json=payload,
            timeout=20
        )
        
        if response.status_code == 200:
            data = response.json()
            bot_response = data["response"]
            formatted_response = format_thinking(bot_response)
            new_history[-1]["content"] = format_message(formatted_response, "assistant")
            yield new_history
        else:
            error_msg = f"API Error: {response.status_code} - {response.text}"
            new_history[-1]["content"] = format_message(error_msg, "assistant")
            yield new_history

    except requests.Timeout:
        error_msg = "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        logger.error(error_msg)
        new_history[-1]["content"] = format_message(error_msg, "assistant")
        yield new_history

    except Exception as e:
        logger.error(f"Error: {e}")
        new_history[-1]["content"] = format_message(f"é”™è¯¯: {str(e)}", "assistant")
        yield new_history

def load_history(session_id: str):
    """Load chat history from backend with timeout"""
    if not session_id:
        return []
    
    try:
        # æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
        response = requests.get(f"{API_URL}/history/{session_id}", timeout=3)
        if response.status_code == 200:
            data = response.json()
            history = data.get("history", [])
            # é™åˆ¶å†å²è®°å½•æ•°é‡ï¼Œé¿å…åŠ è½½è¿‡å¤šæ•°æ®
            MAX_DISPLAY_HISTORY = 20  # åªæ˜¾ç¤ºæœ€è¿‘20æ¡
            recent_history = history[-MAX_DISPLAY_HISTORY:] if len(history) > MAX_DISPLAY_HISTORY else history
            
            formatted_history = []
            for msg in recent_history:
                role = msg["role"]
                content = msg["content"]
                # ç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹ï¼Œä¸é‡å¤æ·»åŠ æ—¶é—´æˆ³
                formatted_history.append({"role": role, "content": content})
            return formatted_history
    except requests.Timeout:
        logger.warning(f"Load history timeout for {session_id}")
    except Exception as e:
        logger.error(f"Failed to load history: {e}")
    return []

# --- UI ---
custom_css = """
/* æ›´åŠ ç°ä»£åŒ–çš„é…è‰² */
body { font-family: 'Helvetica Neue', Arial, sans-serif; }
#chatbot { 
    height: 700px !important; 
    border: 1px solid #e0e0e0;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}
/* æ€è€ƒæ°”æ³¡æ ·å¼ */
.thought-bubble {
    background-color: #f0f4f8;
    border-left: 4px solid #4a90e2;
    padding: 10px;
    margin-bottom: 10px;
    border-radius: 4px;
    font-size: 0.9em;
    color: #555;
}
.thought-content {
    margin-top: 8px;
    white-space: pre-wrap;
}
.message-timestamp {
    font-size: 0.8em;
    color: #666;
}
/* å¼•ç”¨æºæ ·å¼ */
a { color: #4a90e2; text-decoration: none; }
a:hover { text-decoration: underline; }
"""

with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue"), css=custom_css, title="Huatuo-Pro Medical") as demo:
    
    # çŠ¶æ€ç®¡ç†ï¼šä½¿ç”¨ BrowserState æŒä¹…åŒ– SessionID (Gradio 5.x)
    session_state = gr.BrowserState(storage_key="medical_agent_session_id", default_value=None)
    
    with gr.Row():
        # å·¦ä¾§è¾¹æ ï¼šæ§åˆ¶é¢æ¿
        with gr.Column(scale=1, min_width=300):
            gr.Markdown("### ğŸ¥ åŒ»ç–—å¤§æ¨¡å‹")
            gr.Markdown("Based on Qwen3-32B")
            
            with gr.Group():
                mode_radio = gr.Radio(
                    ["Agentæ¨¡å¼", "æ™®é€šé—®ç­”æ¨¡å¼"], 
                    label="æ¨ç†æ¨¡å¼", 
                    value="Agentæ¨¡å¼",
                    info="Agentæ¨¡å¼å…·å¤‡æŸ¥åº“å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›"
                )
                
                with gr.Accordion("ğŸ›ï¸ å‚æ•°è®¾ç½®", open=False):
                    temperature_slider = gr.Slider(0.0, 1.0, value=0.1, label="æ¸©åº¦ (Temperature)", info="åŒ»ç–—åœºæ™¯å»ºè®®ä½è¿·ä»¥ä¿è¯ä¸¥è°¨")
                    max_tokens_slider = gr.Slider(100, MAX_OUTPUT_TOKENS, value=DEFAULT_OUTPUT_TOKENS, label="Max Tokens")
            
            file_upload = gr.File(label="ä¸Šä¼ æ–‡ä»¶")
            
            gr.Markdown("#### ğŸ’¡ æç¤º")
            gr.Markdown("- è¯¢é—®ç–¾ç—…æ—¶è¯·æè¿°æ¸…æ¥šç—‡çŠ¶\n- æ¶‰åŠè¯ç‰©æ—¶è¯·å’¨è¯¢ç¦å¿Œç—‡\n- æ¨¡å‹å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºæœ€ç»ˆåŒ»ç–—è¯Šæ–­")
            
            with gr.Row():
                export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºå¯¹è¯")
                copy_btn = gr.Button("ğŸ“‹ å¤åˆ¶æœ€åå›å¤")
                clean_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="secondary")
            
            with gr.Row():
                load_history_btn = gr.Button("ğŸ”„ åŠ è½½å†å²è®°å½•", variant="secondary", size="sm")
            
            export_file = gr.File(label="å¯¼å‡ºçš„æ–‡ä»¶", visible=False)
            status_display = gr.Textbox(label="çŠ¶æ€", interactive=False, max_lines=1)

        # å³ä¾§ï¼šèŠå¤©ä¸»çª—å£
        with gr.Column(scale=4):
            chatbot = gr.Chatbot(
                label="è¯Šæ–­å¯¹è¯",
                type="messages", 
                avatar_images=(None, "https://img.alicdn.com/imgextra/i4/O1CN01c26iB51UyR3MKMFma_!!6000000002586-2-tps-124-124.png"),
                show_copy_button=True,
                elem_id="chatbot"
            )
            
            with gr.Row():
                msg_input = gr.Textbox(
                    placeholder="è¯·è¾“å…¥æ‚¨çš„åŒ»ç–—å’¨è¯¢é—®é¢˜ (ä¾‹å¦‚: é«˜è¡€å‹æ‚£è€…èƒ½åƒé¦™è•‰å—ï¼Ÿ)",
                    show_label=False,
                    scale=9,
                    container=False
                )
                submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

    # --- äº‹ä»¶ç»‘å®š ---
    
    input_params = [msg_input, chatbot, mode_radio, session_state, file_upload, temperature_slider, max_tokens_slider]
    
    # æäº¤æ¶ˆæ¯
    msg_input.submit(
        fn=chat_stream, 
        inputs=input_params, 
        outputs=chatbot,
        show_progress="hidden"
    ).then(lambda: "", None, msg_input)

    submit_btn.click(
        fn=chat_stream, 
        inputs=input_params, 
        outputs=chatbot
    ).then(lambda: "", None, msg_input)

    # ç‚¹èµäº‹ä»¶
    chatbot.like(on_like, [session_state], None)

    # é¢å¤–åŠŸèƒ½æŒ‰é’®
    clean_btn.click(lambda: [], None, chatbot)
    export_btn.click(handle_export, [chatbot], [export_file, status_display])
    copy_btn.click(copy_last_response, [chatbot], status_display)
    load_history_btn.click(load_history, inputs=[session_state], outputs=[chatbot])

    # é¡µé¢åŠ è½½æ—¶åªåˆå§‹åŒ– sessionï¼Œä¸åŠ è½½å†å²ï¼ˆé¿å…é˜»å¡é¡µé¢æ‰“å¼€ï¼‰
    # å†å²è®°å½•ä¼šåœ¨ç”¨æˆ·é¦–æ¬¡å‘é€æ¶ˆæ¯åè‡ªåŠ¨æ˜¾ç¤ºï¼Œæˆ–ç‚¹å‡»"åŠ è½½å†å²è®°å½•"æŒ‰é’®
    demo.load(init_session, inputs=[session_state], outputs=[session_state])

if __name__ == "__main__":
    print(f"æ­£åœ¨å¯åŠ¨ Web UI...")
    # ç”Ÿäº§ç¯å¢ƒé…ç½®
    demo.queue(max_size=20) # å¼€å¯é˜Ÿåˆ—ï¼Œæ”¯æŒå¤šç”¨æˆ·å¹¶å‘
    try:
        demo.launch(
            server_name="0.0.0.0", 
            server_port=7860, 
            share=False,
            favicon_path=None
        )
    except OSError:
        print("ç«¯å£ 7860 è¢«å ç”¨ï¼Œå°è¯•ä½¿ç”¨ 7861...")
        demo.launch(
            server_name="0.0.0.0", 
            server_port=7861, 
            share=False,
            favicon_path=None
        )
