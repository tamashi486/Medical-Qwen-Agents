import gradio as gr
import os
import sys
import uuid
import logging
import asyncio
from typing import List, Generator

# --- å¼•å…¥åç«¯ (ç¡®ä¿ agent_main.py åœ¨åŒä¸€ç›®å½•) ---
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    sys.path.append(current_dir)
    from medical_agent_pro import MedicalAgentSystem # å‡è®¾ä½ ä¿å­˜çš„åç«¯æ–‡ä»¶åæ˜¯è¿™ä¸ª
except ImportError:
    print("âŒ æœªæ‰¾åˆ°åç«¯æ–‡ä»¶ medical_agent_pro.pyï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å")
    MedicalAgentSystem = None

# --- é…ç½®æ—¥å¿— ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("WebUI")

# --- åˆå§‹åŒ–å•ä¾‹ç³»ç»Ÿ ---
# çœŸæ­£çš„ç”Ÿäº§ç¯å¢ƒé…ç½®åº”è¯¥ä»ç¯å¢ƒå˜é‡è¯»å– (os.getenv)
CONFIG = {
    "db_path": "/data/home/yihui/LLM/data/medical_embedding",
    "embedding_model_path": "/data/home/yihui/LLM/bge-m3",
    "vllm_api_base": "http://localhost:8000/v1",
    "model_name": "qwen-medical"
}

agent_system = None
if MedicalAgentSystem:
    try:
        agent_system = MedicalAgentSystem(**CONFIG)
        logger.info("âœ… åç«¯ç³»ç»ŸåŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")

# --- è¾…åŠ©å‡½æ•° ---

def generate_session_id():
    """ä¸ºæ¯ä¸ª Tab ç”Ÿæˆå”¯ä¸€ä¼šè¯ ID"""
    return str(uuid.uuid4())

def format_history_for_gradio(history):
    """Gradio éœ€è¦ list of dicts æˆ– list of lists"""
    return history

def process_thinking_process(text: str) -> str:
    """ç¾åŒ–æ€è€ƒè¿‡ç¨‹å±•ç¤º"""
    # ç®€å•çš„ XML æ ‡ç­¾è§£æï¼Œä¹Ÿå¯ä»¥ç”¨æ­£åˆ™
    if "<think>" in text and "</think>" in text:
        parts = text.split("</think>")
        thought = parts[0].replace("<think>", "").strip()
        answer = parts[1].strip()
        # ä½¿ç”¨ HTML details æ ‡ç­¾å®ç°æŠ˜å æ•ˆæœ
        return f"""<details class="thought-bubble">
<summary>ğŸ§  æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</summary>
<div class="thought-content">{thought}</div>
</details>

{answer}"""
    return text

# --- æ ¸å¿ƒé€»è¾‘ (Async) ---

async def chat_stream(
    message: str, 
    history: List[dict], 
    mode: str, 
    session_id: str,
    temperature: float
):
    """
    å¼‚æ­¥æµå¼å“åº”å‡½æ•°
    """
    if not message:
        yield history
        return

    # 1. æ›´æ–°ç”¨æˆ·æ¶ˆæ¯
    history.append({"role": "user", "content": message})
    # æ·»åŠ ä¸€ä¸ªç©ºçš„ AI æ¶ˆæ¯å ä½ç¬¦
    history.append({"role": "assistant", "content": "â³ æ­£åœ¨åˆ†æç—…ä¾‹å¹¶æŸ¥é˜…æ–‡çŒ®..."})
    yield history

    try:
        if not agent_system:
            raise Exception("åå°æœåŠ¡æœªè¿æ¥")

        response_content = ""

        if mode == "Agentæ¨¡å¼":
            # å¼‚æ­¥è°ƒç”¨ Agentï¼Œé¿å…é˜»å¡
            # æ³¨æ„ï¼šå¦‚æœåç«¯ chat æ˜¯åŒæ­¥çš„ï¼Œè¿™é‡Œä¼šé˜»å¡ã€‚å»ºè®®åç«¯å®ç° achat
            # è¿™é‡Œæ¼”ç¤ºå‡è®¾åç«¯è¿”å›å®Œæ•´å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿæµå¼æ‰“å­—æœºæ•ˆæœè®©ç”¨æˆ·æ„Ÿè§‰å¿«
            full_response = await agent_system.achat(message, session_id=session_id)
            
            # ç¾åŒ–æ€è€ƒæ ‡ç­¾
            display_response = process_thinking_process(full_response)
            
            # æ¨¡æ‹Ÿæµå¼æ›´æ–° (å¦‚æœåç«¯ä¸æ”¯æŒæµå¼ Agent)
            # å®é™…å¤§å‚é¡¹ç›®ä¼šä½¿ç”¨ LangChain çš„ astream_events æ¥çœŸæµå¼è¾“å‡º
            history[-1]["content"] = display_response
            yield history
            
        else:
            # æ™®é€š LLM æ¨¡å¼ (çœŸæµå¼)
            llm = agent_system.llm
            async for chunk in llm.astream(message):
                response_content += chunk.content
                history[-1]["content"] = response_content
                yield history

    except Exception as e:
        logger.error(f"Error: {e}")
        history[-1]["content"] = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
        yield history

# --- åé¦ˆå›è°ƒ (RLHF æ•°æ®æ”¶é›†) ---
def on_like(x: gr.LikeData, session_id: str):
    """
    æ”¶é›†ç”¨æˆ·ç‚¹èµ/ç‚¹è¸©æ•°æ®
    """
    user_feedback = "Liked" if x.liked else "Disliked"
    logger.info(f"Feedback [{session_id}]: {user_feedback} | Message: {x.value[:50]}...")
    gr.Info(f"æ„Ÿè°¢åé¦ˆï¼å·²è®°å½• ({user_feedback})")

# --- UI å¸ƒå±€ ---
custom_css = """
/* æ›´åŠ ç°ä»£åŒ–çš„é…è‰² */
body { font-family: 'Helvetica Neue', Arial, sans-serif; }
#chatbot { 
    height: 700px !important; 
    border: 1px solid #e0e0e0;
    border-radius: 12px;
}
/* æ€è€ƒæ°”æ³¡æ ·å¼ */
.thought-bubble {
    background-color: #f0f4f8;
    border-left: 4px solid #4a90e2;
    padding: 10px;
    margin-bottom: 10px;
    border-radius: 4px;
    font-size: 0.9em;
    color: #555;
}
.thought-content {
    margin-top: 8px;
    white-space: pre-wrap;
}
/* å¼•ç”¨æºæ ·å¼ (å‡è®¾åç«¯è¿”å›çš„å†…å®¹åŒ…å« Markdown é“¾æ¥æˆ–ç‰¹å®šæ ¼å¼) */
a { color: #4a90e2; text-decoration: none; }
a:hover { text-decoration: underline; }
"""

with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue"), css=custom_css, title="Huatuo-Pro Medical") as demo:
    
    # çŠ¶æ€ç®¡ç†ï¼šä¸ºæ¯ä¸ªç”¨æˆ·åˆ†é…ç‹¬ç«‹çš„ SessionID
    session_state = gr.State(generate_session_id)
    
    with gr.Row():
        # å·¦ä¾§è¾¹æ ï¼šæ§åˆ¶é¢æ¿
        with gr.Column(scale=1, min_width=300):
            gr.Markdown("### ğŸ¥ åé©¼åŒ»ç–—å¤§æ¨¡å‹ä¸“ä¸šç‰ˆ")
            gr.Markdown("Based on Qwen3-32B & RAG")
            
            with gr.Group():
                mode_radio = gr.Radio(
                    ["Agentæ¨¡å¼", "çº¯å¯¹è¯æ¨¡å¼"], 
                    label="æ¨ç†æ¨¡å¼", 
                    value="Agentæ¨¡å¼",
                    info="Agentæ¨¡å¼å…·å¤‡æŸ¥åº“å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›"
                )
                temp_slider = gr.Slider(0.0, 1.0, value=0.1, label="æ¸©åº¦ (Temperature)", info="åŒ»ç–—åœºæ™¯å»ºè®®ä½è¿·ä»¥ä¿è¯ä¸¥è°¨")
            
            gr.Markdown("#### ğŸ’¡ æç¤º")
            gr.Markdown("- è¯¢é—®ç–¾ç—…æ—¶è¯·æè¿°æ¸…æ¥šç—‡çŠ¶\n- æ¶‰åŠè¯ç‰©æ—¶è¯·å’¨è¯¢ç¦å¿Œç—‡\n- æ¨¡å‹å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºæœ€ç»ˆåŒ»ç–—è¯Šæ–­")
            
            clean_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="secondary")

        # å³ä¾§ï¼šèŠå¤©ä¸»çª—å£
        with gr.Column(scale=4):
            chatbot = gr.Chatbot(
                label="è¯Šæ–­å¯¹è¯",
                type="messages", # ä½¿ç”¨æ–°ç‰ˆæ¶ˆæ¯æ ¼å¼
                avatar_images=("user.png", "doctor.png"), # å»ºè®®æ”¾ä¸¤ä¸ªæœ¬åœ°å›¾ç‰‡æ–‡ä»¶
                show_copy_button=True,
                elem_id="chatbot"
            )
            
            with gr.Row():
                msg_input = gr.Textbox(
                    placeholder="è¯·è¾“å…¥æ‚¨çš„åŒ»ç–—å’¨è¯¢é—®é¢˜ (ä¾‹å¦‚: é«˜è¡€å‹æ‚£è€…èƒ½åƒé¦™è•‰å—ï¼Ÿ)",
                    show_label=False,
                    scale=9,
                    container=False
                )
                submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

    # --- äº‹ä»¶ç»‘å®š ---
    
    # æäº¤æ¶ˆæ¯
    input_params = [msg_input, chatbot, mode_radio, session_state, temp_slider]
    
    msg_input.submit(
        fn=chat_stream, 
        inputs=input_params, 
        outputs=chatbot,
        show_progress="hidden" # éšè—é¡¶éƒ¨è¿›åº¦æ¡ï¼Œä½¿ç”¨æµå¼è¾“å‡º
    ).then(lambda: "", None, msg_input) # å‘é€å®Œæ¸…ç©ºè¾“å…¥æ¡†

    submit_btn.click(
        fn=chat_stream, 
        inputs=input_params, 
        outputs=chatbot
    ).then(lambda: "", None, msg_input)

    # ç‚¹èµäº‹ä»¶
    chatbot.like(on_like, [session_state], None)

    # æ¸…ç©º
    clean_btn.click(lambda: [], None, chatbot)

if __name__ == "__main__":
    # ç”Ÿäº§ç¯å¢ƒé…ç½®
    demo.queue(max_size=20) # å¼€å¯é˜Ÿåˆ—ï¼Œæ”¯æŒå¤šç”¨æˆ·å¹¶å‘
    demo.launch(
        server_name="0.0.0.0", 
        server_port=7860, 
        share=False,
        favicon_path=None
    )